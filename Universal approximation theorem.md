

### Cybenko theorem (easy ver)

<https://www.mathematik.uni-wuerzburg.de/fileadmin/10040900/2019/Seminar__Artificial_Neural_Network__24_9__.pdf>

- Universal approximation theorem for shallow network.
- Here, it proves the setting with single layer and at most 2-dimensional input, and 1-dimensional output. (If all the parameters are single, then its formula can be written in simple expression)
- It does not give the formal approach, just explanation of cybenko theorem. so even high-school student can understand this.


### An Overview Of Artificial Neural Networks for Mathematicians

<https://math.uchicago.edu/~may/REU2018/REUPapers/Guilhoto.pdf>

- null


### Universal Approximation of an Unknown Mapping and Its Derivatives Using Multilayer Feedforward Networks

<https://www.inf.ufrgs.br/~engel/data/media/file/cmp121/univ_approx.pdf>

- If the activations are C^k, then NN are dense in H^k, sobolev space.
